import tensorflow as tf
import tensorflow_probability as tfp
import matplotlib.pyplot as plt
import numpy as np

def L(params):
    x1, x2 = params
    return 1/(2.4*np.pi)*tf.math.exp(-1/2*(((x1-2)/0.3)**2 + ((x2-8)/4)**2)) + 1/(0.32*np.pi)*tf.math.exp(-1/2*(((x1-7)/1)**2 + ((x2-12)/0.16)**2))

def logL(params):
    return tf.math.log(L(params))

def logL2(params):
    x1,x2 = params
    z = tf.math.log(1/(2.4*np.pi)*tf.math.exp(-1/2*(((x1-2)/0.3)**2 + ((x2-8)/4)**2))+1/(0.32*np.pi)*tf.math.exp(-1/2*(((x1-7)/1)**2 + ((x2-12)/0.16)**2)))
    if z < -100:
        z = tf.math.log(1/(2.4*np.pi))*(-1/2*(((x1-2)/0.3)**2 + ((x2-8)/4)**2)) + tf.math.log(1/(0.32*np.pi))*(-1/2*(((x1-7)/1)**2 + ((x2-12)/0.16)**2))
    return z
    
num_results = 100
num_chains = 10
num_params = 2
num_burnin_steps = 10

hmc = tfp.mcmc.MetropolisHastings(
    tfp.mcmc.UncalibratedHamiltonianMonteCarlo(
        target_log_prob_fn=logL2,
        step_size=0.2,
        num_leapfrog_steps=3))

def run_chain():
    states = tfp.mcmc.sample_chain(
        num_results=num_results,
        num_burnin_steps=num_burnin_steps,
        #current_state = tf.constant([2.,7.]),
        current_state = tf.random.uniform([num_params],-10.,20.),
        kernel=hmc,
        trace_fn=None)
    return states

chains = [run_chain() for i in range(num_chains)]

samples = np.array([sample.numpy() for sample in chains])
samples = tf.reshape(samples, [num_results*num_chains,num_params])

plt.hist(samples[:,0], 100, histtype = 'step')
plt.xlabel(r"$\theta_1$")
plt.ylabel(r"$p(\theta_1)$")
plt.gca().set_yticks([])
plt.show()

plt.hist(samples[:,1], 100, histtype = 'step')
plt.xlabel(r"$\theta_2$")
plt.ylabel(r"$p(\theta_2)$")
plt.gca().set_yticks([])
plt.show()